{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CE-40959: Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework1: Numpy and Tensorflow  (70pts)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deadline:   2  Esfand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run cells by hitting `Shift` + `Enter`. <br/>\n",
    "We higly recommend you to read each line of code meticulously and try to unserstand what it exactly does. You may want to use the techniques mentioned in this notebook in your next assignments.<br/>\n",
    "You may want to read the two tutorials `Numpy Tutorial` and `TensorFlow Tutorial` first before coming to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from perceptron import Perceptron\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 10.0) # set default size of plots\n",
    "\n",
    "# The following two lines let us reload external modules in the notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1. $L^2$ Distance (12pts)\n",
    "Suppose that we have a matrix called $X1$ which is a numpy ndarray with shape $(N1, D)$. This matrix has $N$ rows and each row corresponds to a $D-$dimensional vector which we call an instance. There is also another matrix named $X2$ with the shape $(N2, D)$. Note that $N1$ is not essentially equal to $N2$. <br/>\n",
    "We want to compute the $L^2$-distance between each instance in the first matrix and each instance in the second matrix. $L^2$-distance or _Euclidean distance_ between two vectors $\\mathbf{p}$ and $\\mathbf{q}$ is defined as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "d(\\mathbf{p}, \\mathbf{q}) = \\sqrt{(p_1 - q_1)^2 + ... +\\:(p_m - q_m)^2}\n",
    "\\end{equation}\n",
    "\n",
    "We want to make a matrix called `dists` in which the $(i, j)$-th entry is the $L^2$-distance between the $i$-th instance in $X1$ and the $j$-th instance in $X2$. <br/>\n",
    "Complete the code of following functions to do this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2_distance_1(x1, x2):\n",
    "    \"\"\"\n",
    "    x1: numpy 2d-array with shape (N1, D)\n",
    "    x2: numpy 2d-array with shape (N2, D)\n",
    "    ouput: dists which is a 2d-array with shape (N1, N2)\n",
    "    \"\"\"\n",
    "    dists = None\n",
    "    ################################################################################\n",
    "    # TODO:                                                                        #\n",
    "    # Compute the L2-distance between i-th instance (0 <= i < N1) in x1 and j-th   #\n",
    "    # instance in x2 (0 <= j < N2) and store it in dists[i, j]. You can use for    #\n",
    "    # loops in you implementation.                                                 #\n",
    "    ################################################################################\n",
    "    pass\n",
    "    ################################################################################\n",
    "    #                                 END OF YOUR CODE                             #\n",
    "    ################################################################################\n",
    "    return dists\n",
    "    \n",
    "\n",
    "def L2_distance_2(x1, x2):\n",
    "    dists = None\n",
    "    ################################################################################\n",
    "    # TODO:                                                                        #\n",
    "    # Compute the L2-distance between i-th instance (0 <= i < N1) in x1 and j-th   #\n",
    "    # instance in x2 (0 <= j < N2) and store it in dists[i, j].                    #\n",
    "    # You have to implement this function with vectorized computations and without #\n",
    "    # any for loops.                                                               #\n",
    "    # Hint: Try to write L2-distance between elements of x1 and x2 in the form of  #\n",
    "    # matrix multiplication.                                                       #\n",
    "    ################################################################################\n",
    "    pass\n",
    "    ################################################################################\n",
    "    #                                 END OF YOUR CODE                             #\n",
    "    ################################################################################\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test your implementation of `L2_distance_1` with the following function. You have to witness a small value as the ouput. we get an ouput of the order of 1e-15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "def test_L2_distance_1():\n",
    "    x1 = np.random.randn(10, 8)\n",
    "    x2 = np.random.randn(8, 8)\n",
    "    \n",
    "    out_correct = pairwise_distances(x1, x2)\n",
    "    out = L2_distance_1(x1, x2)\n",
    "    \n",
    "    print(np.linalg.norm(out - out_correct))  # prints the L2-norm of the difference between your answer and correct answer\n",
    "\n",
    "test_L2_distance_1()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test your implementation of `L2_distance_2`. You should get a small value as the output. Ours is of the order of 1e-14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "def test_L2_distance_2():\n",
    "    x1 = np.random.randn(30, 25)\n",
    "    x2 = np.random.randn(40, 25)\n",
    "    \n",
    "    out_correct = pairwise_distances(x1, x2)\n",
    "    out = L2_distance_2(x1, x2)\n",
    "    \n",
    "    print(np.linalg.norm(out - out_correct))\n",
    "test_L2_distance_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's compare the running time of functions! We have provided the following code snippet to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(1000, 1000)\n",
    "b = np.random.randn(2000, 1000)\n",
    "\n",
    "tic = time.time()\n",
    "L2_distance_1(a, b)\n",
    "toc = time.time()\n",
    "print('Running time of L2_distance_1:', toc - tic, 'seconds')\n",
    "\n",
    "tic = time.time()\n",
    "L2_distance_2(a, b)\n",
    "toc = time.time()\n",
    "print('Running time of L2_distance_2:', toc - tic, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a huge improvement in runnnig time of `L2_distance_2` comparing to `L2_distance_1`. This experiment shows that how vectorized and matrix computations in Numpy could be more effiecient than just naively using for loops in Python. Numpy is a powerful module with a beautiful functional API and many of its functions are implemented in C which results in a great efficiency. Nevertheless, one of the biggest disadvantages of Numpy is that it cannot run on GPU. By using machine learning frameworks such as TensorFlow, PyTorch, Keras, and ... we will sidestep this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2. Computing gradients (12pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem you have to compute the gradient of $out$ which is computed in function `gradients` with respect to $x$, $y$, $z$, $w$, $t$, $l$ (i.e. $\\large{\\frac{\\partial{out}}{\\partial{x}}}$, $\\large{\\frac{\\partial{out}}{\\partial{y}}}$, $\\large{\\frac{\\partial{out}}{\\partial{z}}}$, $\\large{\\frac{\\partial{out}}{\\partial{w}}}$, $\\large{\\frac{\\partial{out}}{\\partial{t}}}$, $\\large{\\frac{\\partial{out}}{\\partial{l}}}$) using the chain rule and save them in $grad\\_x$, $grad\\_y$, $grad\\_z$, $grad\\_w$, $grad\\_t$, $grad\\_l$ and return them.\n",
    "\n",
    "Here is the computations done by `gradients` in a mathematical formation:\n",
    "\\begin{equation}\n",
    "z = matmul(x, y) \\\\\n",
    "w = z^2 \\\\\n",
    "t = \\frac{1}{w} \\\\\n",
    "l = -log(t) \\\\\n",
    "out = \\text{sum  of  elements  of}\\;l\\\\\n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients(x, y):\n",
    "    \"\"\"\n",
    "    x: a numpy 2d-array with shape (N, M)\n",
    "    y: a numpy 2-d array with shape (M, K)\n",
    "    ouput: grad_x, grad_y, grad_z, grad_w, grad_t, grad_l which are numpy ndarrays\n",
    "    \"\"\"\n",
    "    z = np.matmul(x, y)\n",
    "    w = z ** 2\n",
    "    t = 1 / w\n",
    "    l = -np.log(t)\n",
    "    out = np.sum(l)\n",
    "    \n",
    "    \n",
    "    grad_x, grad_y, grad_z, grad_w, grad_t, grad_l = [None] * 6\n",
    "    ################################################################################\n",
    "    # TODO: compute the gradients of out with respect to x, y, z, w, t, l and save #\n",
    "    # them in grad_x, grad_y, grad_z, grad_w, grad_t, grad_l respectively.         #\n",
    "    # Hint: Note that gradient of a scalar with respect to matix M has always the  #\n",
    "    # same shape as M.                                                             #\n",
    "    ################################################################################\n",
    "    pass\n",
    "    ################################################################################\n",
    "    #                                 END OF YOUR CODE                             #\n",
    "    ################################################################################\n",
    "    \n",
    "    return grad_x, grad_y, grad_z, grad_w, grad_t, grad_l\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if you have correctly computed gradients. You have to get small values as the ouput. The largest order of ours is 1e-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gradients():\n",
    "    np.random.seed(42)\n",
    "    x = np.random.randn(3, 4)\n",
    "    y = np.random.randn(4, 3)\n",
    "    grad_x, grad_y, grad_z, grad_w, grad_t, grad_l = gradients(x, y)\n",
    "    \n",
    "    correct_grad_x = [[  3.32621571,   2.48439068,   2.83312268,   1.8754347 ],\n",
    "                      [  0.02298492,   2.49547912,   4.96601427,  -1.63235705],\n",
    "                      [ -3.00303062, -11.9160904,  -16.79683266,  -7.02424337]]\n",
    "    \n",
    "    correct_grad_y = [[ -9.80041543,  -1.26504757,  -1.74360921],\n",
    "                      [ 10.79761188,   1.60070006,   0.95345402],\n",
    "                      [-12.46579728,  -3.86728553,   0.46416181],\n",
    "                      [-13.8342653,   -3.86406485,  -1.41252948]]\n",
    "    \n",
    "    correct_grad_z = [[-2.72460835, -1.23289327, -0.94300016],\n",
    "                      [-1.30528211, -1.33925965,  1.28908465],\n",
    "                      [18.64361586,  2.05814041,  2.07330623]]\n",
    "    \n",
    "    correct_grad_w = [[ 1.85587266,  0.38000645,  0.22231233],\n",
    "                      [ 0.42594034,  0.4484041,   0.41543481],\n",
    "                      [86.89610309,  1.05898549, 1.07464968]]\n",
    "   \n",
    "    correct_grad_t = [[-0.53883007, -2.63153426, -4.49817611],\n",
    "                      [-2.34774662, -2.23013124, -2.40711656],\n",
    "                      [-0.011508,   -0.94430001, -0.9305358 ]]\n",
    "    \n",
    "    correct_grad_l = [[1., 1., 1.],\n",
    "                      [1., 1., 1.],\n",
    "                      [1., 1., 1.]]\n",
    "    \n",
    "    \n",
    "    print('relative error of grad_x:', np.linalg.norm(grad_x - correct_grad_x))\n",
    "    print('relative error of grad_y:', np.linalg.norm(grad_y - correct_grad_y))\n",
    "    print('relative error of grad_z:', np.linalg.norm(grad_z - correct_grad_z))\n",
    "    print('relative error of grad_w:', np.linalg.norm(grad_w - correct_grad_w))\n",
    "    print('relative error of grad_t:', np.linalg.norm(grad_t - correct_grad_t))\n",
    "    print('relative error of grad_l:', np.linalg.norm(grad_l - correct_grad_l))\n",
    "    \n",
    "\n",
    "test_gradients()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3. Jacobian (10pts)\n",
    "We have provided a function called `func` for you below. You have to find out the operations done by this function and then complete the code of `jacobian_func` to compute the jacobian of the output of `func` (i.e. x_4). Note that the Jacobian of a function $\\mathbf{f}$: $\\mathbb{R}^n \\rightarrow \\mathbb{R}^m$ is an $m \\times n$ matrix defined as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/jacobian.png\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    \"\"\"\n",
    "    the input vector x is a numpy 1d-array. \n",
    "    \"\"\"\n",
    "    ones = np.ones_like(x)\n",
    "    x_1 = x - ones\n",
    "    x_2 = x_1.copy()\n",
    "\n",
    "    for i in range(len(x_1)-1):\n",
    "        x_2[i] = x_1[i] * x_1[i+1]\n",
    "\n",
    "    x_3 = x_2[:-1]\n",
    "    x_4 = x_3 ** 2\n",
    "    \n",
    "    return x_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobian_func(x):\n",
    "    \"\"\"\n",
    "    x is the same input passed to func on which the computations are done.\n",
    "    you have to return the jacobian of the output of func.\n",
    "    \"\"\"\n",
    "    ################################################################################\n",
    "    # TODO: consider func and its output x_4 and compute its jacobian.             #\n",
    "    # x is the same input we pass to function func.                                #\n",
    "    ################################################################################\n",
    "    pass\n",
    "    ################################################################################\n",
    "    #                                 END OF YOUR CODE                             #\n",
    "    ################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check your implementation of `jacobian_func`. You have to get a small value as the ouput. We get 1e-8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_jacobian_func():\n",
    "    np.random.seed(42)\n",
    "    a = np.random.randn(7)\n",
    "    jacobian = jacobian_func(a)\n",
    "    correct_jacobian = [[-1.30416021, -0.57663705, 0., 0., 0., 0., 0.],\n",
    "                        [ 0., -0.28257039, -0.9129416, 0., 0., 0., 0.],\n",
    "                        [ 0., 0., -0.19275681, 0.12984045, 0., 0., 0.],\n",
    "                        [ 0., 0., 0., 1.59328969, -0.67523056, 0., 0.],\n",
    "                        [ 0., 0., 0., 0., -3.75946327, -3.75951328, 0.],\n",
    "                        [ 0., 0., 0., 0., 0., -0.82807501, 1.76439116]]\n",
    "    print(np.linalg.norm(jacobian - correct_jacobian))\n",
    "test_jacobian_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4. Data manipulation (12pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem you should load MNIST dataset in the format of numpy arrays.<br/> \n",
    "MNIST is a large database of handwritten digits that is commonly used in the field of machine learning. This dataset contains 60,000 training images and 10,000 testing images. We have provided this dataset saved in some files in the `data` directory for you. Training data has been saved in 5 files (`train1.npy`, ..., `train5.npy`) and test data file is `test.npy`. Labels are also stored in two files `labels_train`, `labels_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(root_path):\n",
    "    \"\"\"\n",
    "    root_path: the root directory of data files.\n",
    "    outputs:\n",
    "    1) test_data: test data which is a numpy array of shape (10000, 784).\n",
    "    2) train_data_array: a Python list containing 5 numpy 2d-arrays each one of them has the shape (12000, 784).\n",
    "    3) test_labels: a numpy array with shape (10000, ) containing the labels (0 to 9) of the test set images.\n",
    "    4) train_labels: a numpy array with shape (60000, ) containing the labels (0 to 9) of the training set images.\n",
    "    \"\"\"\n",
    "    train_data_file_names = ['train{}.npy'.format(x) for x in range(1, 6)]\n",
    "    test_data_file_name = 'test.npy'\n",
    "    test_labels_file_name = 'labels_test.npy'\n",
    "    train_labels_file_name = 'labels_train.npy'\n",
    "    \n",
    "    train_data_list = []\n",
    "    for file_name in train_data_file_names:\n",
    "        file_path = os.path.join(root_path, file_name)\n",
    "        ################################################################################\n",
    "        # TODO: provided the file path, load the train data in the form of numpy array #\n",
    "        # and append it to the end of train_data_list.                                 #\n",
    "        ################################################################################\n",
    "        pass\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "    \n",
    "    ################################################################################\n",
    "    # TODO: load the test data, test labels and train labels in the form of numpy  #\n",
    "    # arrays as well and save them in test_data, test_labels and train_labels.     #                                                              #\n",
    "    ################################################################################\n",
    "    pass\n",
    "    ################################################################################\n",
    "    #                                 END OF YOUR CODE                             #\n",
    "    ################################################################################\n",
    "    \n",
    "    return test_data, train_data_list, test_labels, train_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test your implementation of `load_data` with the following function. You have to get no erros after running this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_load_data(root_path):\n",
    "    test_data, train_data_list, test_labels, train_labels = load_data('data')\n",
    "    assert test_data.shape == (10000, 784)\n",
    "    assert len(train_data_list) == 5\n",
    "    assert test_labels.shape == (10000, )\n",
    "    assert train_labels.shape == (60000, )\n",
    "    assert train_data_list[0].shape == (12000, 784)\n",
    "    print('You have successfully loaded the data!')\n",
    "    \n",
    "test_load_data('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each one of the samples of MNIST dataset is a $28\\times28$ graysacle image. Pixel values are between 0 and 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/mnist.jpg\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Concatenation\n",
    "You have loaded the training data as a list of five numpy arrays, each one of them has the shape $(12000, 784)$. We need to concatenate these five arrays into one array with shape $(60000, 784)$. <br/> \n",
    "In this part you should Implement a function for cancatenating a set of numpy nd-arrays given to you in a Python list (Note that the list does not necessarily contain five arrays and the arrays might not be 2d-arrays! You have to implement the function for general case). You have to do the concatenation along the first dimension i.e. axis=0. You are **not** allowed to use `np.concatenate` in your code and you have to do it from scratch using Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(list_of_arrays):\n",
    "    \"\"\"\n",
    "    list_of_arrays is a non-empty list of numpy arrays (with arbitrary number of dimensions) with the SAME shape\n",
    "    output: array_concat which is a numpy ndarray\n",
    "    \"\"\"\n",
    "    array_concat = None\n",
    "    ################################################################################\n",
    "    # TODO: you have to concatenate the numpy arrays along the first axis into one #\n",
    "    # single numpy array called array_concat.                                      #\n",
    "    # You are not allowed to use np.concatenate in your implementation.            #\n",
    "    # for example if list_of_arrays is [arr1, arr2] and                            #\n",
    "    # arr1: [[1, 1, 1], [1, 1, 1]] (shape: (2, 3))                                 #\n",
    "    # arr2: [[2, 2, 2], [2, 2, 2]] (shape: (2, 3))                                 #\n",
    "    # you have to return                                                           #\n",
    "    # output: [[1, 1, 1], [1, 1, 1], [2, 2, 2], [2, 2, 2]] (shape: (4,3))          #\n",
    "    # In fact, you have to implement the function np.cancatenate() from scratch    #\n",
    "    # by yourself.                                                                 #\n",
    "    ################################################################################\n",
    "    pass\n",
    "    ################################################################################\n",
    "    #                                 END OF YOUR CODE                             #\n",
    "    ################################################################################\n",
    "    return array_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test your implementation with the following function. You have to get no errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_concat():\n",
    "    t1 = [np.random.randn(10) for _ in range(10)]\n",
    "    t2 = [np.random.randn(5, 3) for _ in range(5)]\n",
    "    t3 = [np.random.randn(1, 5, 3, 4) for _ in range(3)]\n",
    "    t3 = [np.random.randn(100, 5, 2, 5, 14) for _ in range(3)]\n",
    "    t1_concat, t2_concat, t3_concat = concat(t1), concat(t2), concat(t3)\n",
    "    assert np.array_equal(t1_concat, np.concatenate(t1, axis=0))\n",
    "    assert np.array_equal(t2_concat, np.concatenate(t2, axis=0))\n",
    "    assert np.array_equal(t3_concat, np.concatenate(t3, axis=0))\n",
    "    print('you have successfully implemented concatenation!')\n",
    "\n",
    "test_concat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's concat `train_data_list` with your `concat` function and save it in `train_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, train_data_list, test_labels, train_labels = load_data('data')\n",
    "train_data = concat(train_data_list)\n",
    "assert train_data.shape == (60000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is visualizing some of the digits we have loaded. But, first we have to reshape each sample into a 2d-array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Reshape\n",
    "Complete the function `reshape` to reshape a flat array with shape $(N, d^2)$ to an array with shape $(N, d, d)$. You can use `np.reshape` in your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(x):\n",
    "    \"\"\"\n",
    "    x is an array with shape (N, d*d)\n",
    "    output: x_reshaped which is numpy 3d-array with shape (N, d, d)\n",
    "    \"\"\"\n",
    "    x_reshaped = None\n",
    "    ################################################################################\n",
    "    # TODO: You have to reshape the input x which has the shape (N, d^2) to an     #\n",
    "    # array with shape (N, d, d) and save it in x_reshaped.                        #                                          \n",
    "    ################################################################################\n",
    "    pass\n",
    "    ################################################################################\n",
    "    #                                 END OF YOUR CODE                             #\n",
    "    ################################################################################\n",
    "    return x_reshaped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test you implementation of `reshape` with the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reshape():\n",
    "    a = np.empty([531, 100])\n",
    "    b = np.empty([3000, 4096])\n",
    "    c = np.empty([10000, 10000])\n",
    "    a_reshaped, b_reshaped, c_reshaped = reshape(a), reshape(b), reshape(c) \n",
    "    assert a_reshaped.shape == (531, 10, 10)\n",
    "    assert b_reshaped.shape == (3000, 64, 64)\n",
    "    assert c_reshaped.shape == (10000, 100, 100)\n",
    "    print('you have successfully implemented reshape!')\n",
    "    \n",
    "test_reshape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Visualization\n",
    "Let's apply your reshape function on some of the digit samples in the dataset and visualize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_class = 7\n",
    "\n",
    "for i in range(10):\n",
    "    idxs = np.where(train_labels==i)[0]\n",
    "    idxs = idxs[:samples_per_class]\n",
    "    sample_imgs = reshape(train_data[idxs])\n",
    "    \n",
    "    for j, idx in enumerate(idxs):\n",
    "        plt_idx = i * samples_per_class + j + 1\n",
    "        plt.subplot(10, samples_per_class, plt_idx)\n",
    "        plt.imshow(sample_imgs[j])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Split\n",
    "During this course, you will see that we mostly partition our training data into train and validation set. Implement the following function to split the given data into two sets provided the ratio between the size of validation set and the whole training dataset. You **cannot** use `np.array_split()` or `np.split()` in the first function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_1(x, val_ratio=0.1):\n",
    "    \"\"\"\n",
    "    x: a numpy ndarray\n",
    "    val_ratio: ratio between the size of validation set and x\n",
    "    ouputs: x_train, x_val: numpy ndarrays\n",
    "    \"\"\"\n",
    "    x_train, x_val = None, None\n",
    "    #################################################################################\n",
    "    # TODO: split the input x (numpy ndarray) into two sets x_train and x_val given #\n",
    "    # the ratio between the number of the elements in the validation set (x_val)    # \n",
    "    # and the number of elements in x (e.g. if val_ratio=0.2 and                    #\n",
    "    # x's shape is (1000, 2, 3, 5) then x_train's shape would be (800, 2, 3, 5)     #\n",
    "    # and x_val's shape would be (200, 2, 3, 5)). Note that if N is                 #\n",
    "    # the number of instances in x then N * (1 - val_ratio) first instances would   #\n",
    "    # be x_train and the last N * val_ratio instances would be x_val.               #\n",
    "    # you cannot use np.split or np.array_split in your implementation.             #                    \n",
    "    #################################################################################\n",
    "    pass\n",
    "    #################################################################################\n",
    "    #                                 END OF YOUR CODE                              #\n",
    "    #################################################################################\n",
    "    return x_train, x_val\n",
    "\n",
    "def split_train_2(x, val_ratio=0.1):\n",
    "    \"\"\"\n",
    "    x: a numpy ndarray\n",
    "    ratio: ratio between the size of validation set and size of input x\n",
    "    ouputs: x_train, x_val: numpy ndarrays\n",
    "    \"\"\"\n",
    "    #################################################################################\n",
    "    # TODO: implement the above function with np.split.                             #                \n",
    "    #################################################################################\n",
    "    pass\n",
    "    #################################################################################\n",
    "    #                                 END OF YOUR CODE                              #\n",
    "    #################################################################################\n",
    "    return x_train, x_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. Shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffling data serves the purpose of reducing variance and making sure that models remain general and overfit less. You will want to shuffle the data to make sure that the training/test/validation sets are representative of the overall distribution of the data.<br/>\n",
    "Consider the function `shuffle` which takes two parameters: \n",
    "1. $x$ which is a numpy nd-array with shape $(N, d1, d2, ...)$ \n",
    "2. $y$ which is a numpy 1d-array with shape $(N, )$.\n",
    "\n",
    "You have to complete this function so that it shuffles x and y with the **same** order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(x, y):\n",
    "    \"\"\"\n",
    "    x: a numpy nd-array with shape (N, d1, d2, ...)\n",
    "    y: a numpy 1d-array with shape (N, )\n",
    "    output: x_shuffled and y_shuffled\n",
    "    \"\"\"\n",
    "    x_shuffled, y_shuffled = None, None\n",
    "    ################################################################################\n",
    "    # TODO: You have to shuffle x and y with the                                   #\n",
    "    # same order. for example if x is [[1, 1, 1], [2, 2, 2], [3, 3, 3]]            #\n",
    "    # and y is [1, 2, 3] then a valid shuffling would be                           #\n",
    "    # x_shuffled: [[3, 3, 3], [1, 1, 1], [2, 2, 2]]                                #\n",
    "    # y_shuffled: [3, 1, 2]                                                        #\n",
    "    # Note that the only condition you have to satisfy is that the order of        #\n",
    "    # shuffling for both x and y should be the same and there is no other          #\n",
    "    # limitation on the order. Therefore there may be more than one valid          #\n",
    "    # shuffling.                                                                   #\n",
    "    # you can use np.random.shuffle() for shuffling.                               #                                                    #                                          \n",
    "    ################################################################################\n",
    "    pass\n",
    "    ################################################################################\n",
    "    #                                 END OF YOUR CODE                             #\n",
    "    ################################################################################\n",
    "    return x_shuffled, y_shuffled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that your implementation is correct with the following simple test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_shuffle():\n",
    "    x = np.array([[1, 1, 1], [2, 2, 2], [3, 3, 3]])\n",
    "    y = np.array([1, 2, 3])\n",
    "    x_shuffled, y_shuffled = shuffle(x, y)\n",
    "    print(x_shuffled)\n",
    "    print(y_shuffled)\n",
    "\n",
    "test_shuffle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5. Perceptron (12pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, the perceptron is an algorithm for supervised learning of binary classifiers. A binary classifier is a function which can decide whether or not an input, represented by a vector of numbers, belongs to some specific class. It is a type of linear classifier, i.e. a classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"image/percep.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like most other techniques for training linear classifiers, the perceptron generalizes naturally to multiclass. Each training instance is a feature vector $\\normalsize x$ and a class label $\\normalsize y^*$. Each class has a weight vector $\\normalsize w_{y}$. The feature vector is multiplied by the weight vectors and score of class $\\normalsize y$ will be $\\normalsize x.w_{y}$. The resulting scores is used to choose the predicted class:\n",
    "\\begin{equation}\n",
    "\\normalsize\n",
    "\\hat{y} = \\underset{y}{\\operatorname{argmax}} x.w_{y}\n",
    "\\end{equation}\n",
    "\n",
    "For learning, perceptron starts with all weights equal to zero and iterates over the examples one by one, predicting an output for each. It leaves the weights unchanged when the predicted output matches the target. If the prediction is wrong, it lowers the score of wrong answer and raise the score of right answer. Therefore, the updates become:\n",
    "\\begin{equation}\n",
    "\\normalsize\n",
    "w_{\\hat{y}} = w_{\\hat{y}} - x \\\\\n",
    "\\normalsize\n",
    "w_{y^*} = w_{y^*} + x\n",
    "\\end{equation}\n",
    "where $\\hat{y}$ is the predicted wrong class and $y^*$ is the right class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open `perceptron.py` and complete the code of the perceptron model in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from perceptron import Perceptron\n",
    "model = Perceptron(784, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the functions of the previous problem to preprocess the data and make 4 sets `X_train`, `X_val`, `y_train`, `y_val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "test_data, train_data_list, test_labels, train_labels = load_data('data')\n",
    "train_data = concat(train_data_list)\n",
    "\n",
    "print(train_data.shape)  # Expected ouput: (60000, 784)\n",
    "print(test_data.shape)  # Expected ouput: (10000, 784)\n",
    "print(test_labels.shape)  # Expected ouput: (10000,)\n",
    "print(train_labels.shape)  # Expected ouput: (60000,)\n",
    "\n",
    "train_data_shuffled, train_labels_shuffled = shuffle(train_data, train_labels)\n",
    "X_test, y_test = test_data, test_labels\n",
    "X_train, X_val = split_train_1(train_data, val_ratio=1/60)\n",
    "print(X_train.shape, X_val.shape)  # Expected ouput: (59000, 784) (1000, 784)\n",
    "y_train, y_val = split_train_1(train_labels, val_ratio=1/60)\n",
    "print(y_train.shape, y_val.shape)  # Expected ouput: (59000,) (1000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding 1s to the end of feature vectors to be multiplied by bias term of weights\n",
    "# WARNING: RUN THIS CELL ONLY ONCE!\n",
    "X_val = np.insert(X_val, 0, 1, axis=1)\n",
    "X_train = np.insert(X_train, 0, 1, axis=1)\n",
    "X_test = np.insert(X_test, 0, 1, axis=1)\n",
    "print(X_train.shape)  # Expected ouput: (59000, 785)\n",
    "print(X_val.shape)  # Expected ouput: (1000, 785)\n",
    "print(X_test.shape)  # Expected ouput: (10000, 785)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train your model on the training set. Meanwhile, the accuracy on the validation set is printed out to make sure that the model is training well. Your model has to reach an accuracy higher than 85% on the validation set. We have provided this code for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accs = []\n",
    "for i, (x, y) in enumerate(zip(X_train, y_train)):\n",
    "    model.train(x, y)\n",
    "    if i % 1000 == 0:\n",
    "        val_res =  [model.predict(x_val) == y_val for x_val, y_val in zip(X_val, y_val)]\n",
    "        val_acc = np.sum(val_res) / len(val_res)\n",
    "        val_accs.append(val_acc*100)  # recording the accuray to be plotted after training \n",
    "        print(\"iteration number %d, accuracy on validation set: %.2f%%\" % (i, 100*val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the accuracy on validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_accs)\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.xlabel('iteration number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's test your model on the test set. You have to get an accuracy above 85%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res =  [model.predict(x_test) == y_test for x_test, y_test in zip(X_test, y_test)]\n",
    "test_acc = np.sum(test_res) / len(test_res)\n",
    "print(\"accuracy on test set: %.2f%%\" % (100*test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6. Implementing a  basic computation in Tensorflow (12pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Programming with Tensorflow has the following two main steps:\n",
    "\n",
    "1. Creating a computational model (or more precisely a computational graph). \n",
    "3. Creating a session and run your computational model with the session.\n",
    "\n",
    "In this notebook we just want to familiarize you with how Tensorflow works. In your next assignments you will learn how to design your machine learning models with Tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to build a computational graph with the following properties:\n",
    "* $w1, w2, b1, b2$: Variables with shapes $(50, 40)$, $(100, 40)$, $(40,)$, $(40, )$ respectively. Use `tf.get_variable` and initialize them with `tf.random_normal_initializer`.\n",
    "* $\\normalsize x$, $\\normalsize y \\:$: pacleholders to feed the data to the model with shapes $(200, 50)$, $(150, 100)$ respectively.\n",
    "\n",
    "Operations:\n",
    "1. $z = xw_{1} + b_{1}$\n",
    "2. $a = z^2$\n",
    "3. $k = yw_{2} + b_{2}$\n",
    "4. $l = ak^{T}$ \n",
    "5. $s$ = Sum of the elements of $l$\n",
    "\n",
    "Ouputs:  \n",
    "you have to print the numpy value of $s$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Building the computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Clearing the default graph stack and resets the global default graph\n",
    "tf.reset_default_graph()\n",
    "np.random.seed(42)\n",
    "tf.set_random_seed(42)\n",
    "#################################################################################\n",
    "# TODO: build the computational graph here. use tf.get_variable for variables   #\n",
    "# and initialize them with tf.random_normal_initializer                         #              \n",
    "#################################################################################\n",
    "pass\n",
    "#################################################################################\n",
    "#                                 END OF YOUR CODE                              #\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Runnning the computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = np.random.randn(200, 50)\n",
    "y_input = np.random.randn(150, 100)\n",
    "#################################################################################\n",
    "# TODO: Run the computational graph with a session and feed x_input and y_input #\n",
    "# to the placeholders and print out the numpy value of s                        # \n",
    "#################################################################################\n",
    "pass\n",
    "#################################################################################\n",
    "#                                 END OF YOUR CODE                              #\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "             s_np:\n",
    "        </td>\n",
    "        <td>\n",
    "            -5759624.0\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Computing gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike numpy, We can get the gradients of a tensor with respect to other tensors easily in Tensorflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# TODO: Compute gradient of s with respect to x, y, a, l, w1, b2 and save them  #\n",
    "# in numpy format in grad_x_np, grad_y_np, grad_a_np, grad_l_np, grad_w1_np,    #\n",
    "# grad_b2_np.                                                                   # \n",
    "# Hint: use tf.gradients.                                                       #\n",
    "#################################################################################\n",
    "pass\n",
    "#################################################################################\n",
    "#                                 END OF YOUR CODE                              #\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test if the gradients have the right shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert grad_x_np.shape == (200, 50)\n",
    "assert grad_y_np.shape == (150, 100)\n",
    "assert grad_a_np.shape == (200, 40)\n",
    "assert grad_l_np.shape == (200, 150)\n",
    "assert grad_w1_np.shape == (50, 40)\n",
    "assert grad_b2_np.shape == (40,)\n",
    "print('You have successfully computed gradients!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
