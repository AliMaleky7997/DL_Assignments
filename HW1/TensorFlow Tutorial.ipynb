{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tensor\n",
    "Please read the tutorial in the following link first:\n",
    "https://www.tensorflow.org/guide/tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's review the tutorial by coding it here. Feel free to change the code cells and inspect the changes in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Creating Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When writing Tensorflow programs the main object you manipulate and pass is `tf.Tensor`. Some types of tensors are special:\n",
    "* `tf.constant`\n",
    "\n",
    "* `tf.Variable`\n",
    "\n",
    "* `tf.placeholer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([1,2,3,4,5], name='x')\n",
    "y = tf.constant([[1,2,3,4,5],[2,0,3,4,2]], name='y')\n",
    "v = tf.Variable([1., 2.33, 3.11], dtype=tf.float32, name='v')\n",
    "s = tf.Variable(['Hello!'], dtype=tf.string, name='s')\n",
    "p = tf.placeholder(name='p', shape=[None, 10], dtype=tf.float32) # number of elements in the first dimension will be determined when we run a session. \n",
    "print(x)\n",
    "print(y)\n",
    "print(v)\n",
    "print(s)\n",
    "print(p)\n",
    "print('\\n')\n",
    "print(type(x))\n",
    "print(type(v))\n",
    "print(type(s))\n",
    "print(type(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Shape and Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = tf.zeros([1, 2, 3], dtype=tf.int32)\n",
    "print(z.shape)  # What do you expect to get as the ouput?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(z.shape))  # What do you expect to get as the ouput?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = tf.Variable(initial_value=[[2, 3]], dtype=tf.int32)\n",
    "r = tf.rank(var1)\n",
    "print(r) # What do you expect to get as the ouput?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Referring to tf.Tensor slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank 1\n",
    "vector = tf.constant([1, 2, 3, 4])\n",
    "x = vector[1]\n",
    "y = vector[0:2]\n",
    "i = tf.constant(2)\n",
    "print(x)\n",
    "print(y)\n",
    "print(vector[i])\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# rank 2\n",
    "mat = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "z = mat[2]\n",
    "w = mat[0:2, 1]\n",
    "t = mat[:, 0:2]\n",
    "print(z)\n",
    "print(w)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.ones([2, 3, 4])\n",
    "b = tf.reshape(a, [4, 6])\n",
    "c = tf.reshape(a, [-1])\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([1, 2, 6])  # Can you guess the datatype?\n",
    "b = tf.cast(a, dtype=tf.float64)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow uses a dataflow graph to represent your computation in terms of the dependencies between individual operations. For example, in a Tensorflow graph, the `tf.matmul` operation would correspond to a single node with two incoming edges (the matrices to be multiplied) and one outgoing edge. <br/>\n",
    "A `tf.Graph` contains two relevant kinds of information:\n",
    "* **Graph structure**: The nodes and edges of the graph, indicating how individual operations are composed together.\n",
    "* **Graph collections**: Tensorflow provides a general mechanism for storing collections of metadata in `tf.Graph`. (collections are out of the scope of this tutorial, so don't bother yourself if it seems confusing. But, you can read more about them [here](https://www.tensorflow.org/guide/graphs) if you'd like.)<br/>\n",
    "\n",
    "Most Tensorflow programs start with a dataflow graph construction phase. In this phase, you invoke Tensorflow API functions that constructs new `tf.Operation` (node) and `tf.Tensor` (edge) objects and add them to a `tf.Graph` instance. \n",
    "Tensorflow provides a **default graph** that is an implicit argument to all functions in the same context. For example:\n",
    "* Calling `tf.constant(42.0)` creates a single `tf.Operation` that produces the value 42.0, adds it to the default graph, and returns a `tf.Tensor` that represents the value of the constant.\n",
    "* Calling `tf.matmul(x, y)` creates a single `tf.Operation` that multiplies the values of `tf.Tensor` objects `x` and `y`, adds it to the default graph, and returns a `tf.Tensor` that represents the result of the multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, consider the following code. It builds a computational graph (which is the default graph) with 3 nodes: `x`, `y`, `z`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the graph...\n",
    "x = tf.constant(3)\n",
    "y = tf.constant(4)\n",
    "z = x * y\n",
    "# 3 nodes have been added to the graph by far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eech Tensor object resides in a graph. By running the following code snippet you will see that `x`, `y`, `z` are all in the default graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.graph is tf.get_default_graph())\n",
    "print(y.graph is tf.get_default_graph())\n",
    "print(z.graph is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can clear the nodes in the default graph and reset it by using `tf.reset_default_graph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(3) \n",
    "print(x.graph is tf.get_default_graph())\n",
    "tf.reset_default_graph()\n",
    "print(x.graph is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the computational graph is built, you can run the computation that produces a particular `tf.Tensor` and fetch the values assigned to it. With `tf.Session()` you can run a computational graph. We usually use a session with a context manager in Python, So we don't need to worry about closing the session. you can read more about context managers in Python [here](https://en.m.wikibooks.org/wiki/Python_Programming/Context_Managers) if you'd like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the computational graph...\n",
    "# in this example the computational graph is so simple and contains only one tf.constant\n",
    "x = tf.constant([1, 2, 3, 4, 5], name ='x')\n",
    "\n",
    "# running the computational graph with a session\n",
    "with tf.Session() as sess:\n",
    "    x_np = sess.run(x)  # every tensor after runing session on it would give us a numpy array\n",
    "    \n",
    "print(type(x_np))\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A more sophisticated example\n",
    "# in this example we use arithmetic operations too\n",
    "\n",
    "# building the computational graph...\n",
    "x = tf.constant([1, 2, 3, 4], dtype=tf.float32)\n",
    "y = x ** 2  # The overloaded operators are available in Tensorflow\n",
    "z = y - 1\n",
    "print(z)\n",
    "\n",
    "# running the computational graph with a session\n",
    "with tf.Session() as sess:\n",
    "    z_np = sess.run(z)\n",
    "    print(z_np)  # What output do you expect to get?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, We don't want to work only with constant tensors. In fact there should be a way to feed the data into our computational model. This can be done by using `tf.placeholder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the computational graph...\n",
    "# we will feed the data into x when we run the graph\n",
    "x = tf.placeholder(name='x', shape=[2, 3], dtype=tf.float32)\n",
    "y = x / 2\n",
    "\n",
    "# running the computational graph with a session\n",
    "with tf.Session() as sess:\n",
    "    x_np = np.random.randn(2, 3)\n",
    "    y_out = sess.run(y, feed_dict={x: x_np})  # feeding the data to feeddict parameter of sess.run() as a Python dictionary\n",
    "print(y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no need to specify the number of elements in each dimension of a placeholder. We will use this nice property later when we feed mini-batches of data with not necessarily a fixed size to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(name='x', shape=[None, 3], dtype=tf.float32)\n",
    "\n",
    "x_np_1 = np.random.randn(4, 3)\n",
    "x_np_2 = np.random.randn(2, 3)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    x_out1 = sess.run(x, feed_dict={x: x_np_1})\n",
    "    x_out2 = sess.run(x, feed_dict={x: x_np_2})\n",
    "    print('x_out1:\\n', x_out1)\n",
    "    print('x_out2:\\n', x_out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you witnessed above, you can run a computational graph many times (in this case the computational graph was consisted of only one placeholder), each time with a different input. Thus, you build the graph once but you can run it many times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also evaluate the value of a tensor with `Tensor.eval()` method. The eval method only works when a default session is active. `Tensor.eval()` returns a numpy array with the same contents as the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([5, 11, 22, 0], dtype=tf.float32)\n",
    "\n",
    "\n",
    "# creating a session for evaluating a\n",
    "# if you run tf.eval() without creating session you will get an error\n",
    "with tf.Session() as sess:\n",
    "    print(a.eval())\n",
    "    print(type(a.eval()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Supplementary notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `tf.Variable` represents a tensor whose value can be changed by running ops on it. The `Variable()` constructor requires an intitial value for the variable, which can be a Tensor of any type and shape. The initial value defines the type and shape of the variable. After construction, the type and shape of the variable are fixed. The value can be changed using one of the assign methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.Variable(initial_value=[2,3,8], name='v')\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)  # initialize variables\n",
    "    v_out = sess.run(v)\n",
    "print(v_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you have to run the initialization of variables residing inside your computational graph before running any other operations on them. Otherwise, you will get an error! The operation init above does this initialization when we run sess on it. So don't forget: **All variables needs to be initialized!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.Variable(initial_value=tf.zeros([4, 5]), dtype=tf.float32)\n",
    "v = v + 1  # you can normaly treat with variables like any other tensor in computations\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())  # a shorter way of initializing variables\n",
    "    v_out = sess.run(v)\n",
    "    print(v_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(initial_value=tf.zeros([4, 5]), dtype=tf.float32)\n",
    "t = tf.Variable(initial_value=tf.ones([4, 5]), dtype=tf.float32)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(w.initializer)  # another way of initializing a variable\n",
    "    t.initializer.run()  # another way of initializing a variable\n",
    "    w_np = sess.run(w)\n",
    "    t_np = sess.run(t)\n",
    "    print(w_np)\n",
    "    print(t_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although you can create variables with the `tf.Variable()` constructor, the preferred way of creating variables is using `tf.get_variable()`. This function requires you to specify the variable's name. It also allows you to reuse a previously created variable of the same name (don't worry if it seems confusing! you will work more with this function in your next assignments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close the default graph stack and resets the global default graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "var1 = tf.get_variable(name='var1', shape=[1, 2, 3], initializer=tf.zeros_initializer)\n",
    "var2 = tf.get_variable(name='var2', shape=[1, 2, 3], initializer=tf.random_normal_initializer)\n",
    "\n",
    "print(var1)\n",
    "print(var2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    var1_np, var2_np = sess.run([var1, var2])  # running a session on multiple tensors at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assign a value to a variable, you can use the methods `assign`, `assign_add`, `assign_sub`, ... . For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "var3 = tf.get_variable('var3', shape=(1, 2), initializer=tf.zeros_initializer())\n",
    "assignment_operation = var3.assign_add(tf.ones([1, 2]))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    output = sess.run(assignment_operation)\n",
    "    print(output, '\\n')\n",
    "    \n",
    "    var3_np = sess.run(var3)\n",
    "    print(var3_np, '\\n')\n",
    "    \n",
    "    var3_np_1 = sess.run(var3.read_value())  # reading the value of a variable\n",
    "    print(var3_np_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the link to a tutorial for reading more about variables:\n",
    "https://www.tensorflow.org/guide/variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### name scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow uses namespaces to organize tensors/variables and operations. An example of tensor name is `scope_outer/scope_inner/tensor_a:0`. `tensor_a` is the actual name of the tensor. The suffix `:0` is the endpoint used to give the tensors returned from an operation unique identifiers, i.e. `:0` is the first tensor, `:1` is the second and so on.\n",
    "\n",
    "Some medium or high level APIs like Keras will handle scope naming for you. But if you want to program in low-level in Tensorflow you have to do this manually. This is usually done by using `tf.name_scope` or `tf.variable_scope`. [This link](https://stackoverflow.com/questions/35919020/whats-the-difference-of-name-scope-and-a-variable-scope-in-tensorflow/43581502#43581502) gives a great explanation to the differences between these two. It turns out there is only one difference, `tf.variable_scope` affects `tf.get_variable` while `tf.name_scope` does not. `tf.variable_scope` also has a parameter `reuse` which allow you to reuse the same variable (with the same name in the same namespace) in the different part of the code without having to pass a reference to that variable around. Usually you would want to use `variable_scope` unless there is a need to put operations and variables in different levels of namespaces.\n",
    "\n",
    "Don't worry if you are confused. The goal of this notebook is just familiarizing you with Tensorflow and we are not aiming to work with namescopes in this assignment. You will learn exactly how to work with them in your next assignments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope('scope1'):\n",
    "    x = tf.constant(2, name = 'y')\n",
    "    y = tf.constant(2, name = 'y')\n",
    "    c = tf.constant(2, name = 'w')\n",
    "\n",
    "print(x.name)\n",
    "print(y.name)\n",
    "print(c.name)\n",
    "print('\\n')\n",
    "\n",
    "with tf.name_scope('scope2'):\n",
    "    c1 = tf.constant(2,name = 'w')\n",
    "    c2 = tf.constant(2,name = 'w1')\n",
    "\n",
    "print(c1.name)\n",
    "print(c2.name)\n",
    "print('\\n')\n",
    "\n",
    "with tf.name_scope('scope3'):\n",
    "    d1 = tf.constant(2,name = 'w')\n",
    "    d2 = tf.constant(2,name = 'w1')\n",
    "    w2 = tf.get_variable(name='w2', shape=[1, 2], dtype=tf.float32)\n",
    "\n",
    "print(d1.name)\n",
    "print(d2.name)\n",
    "print(w2.name)\n",
    "print('\\n')\n",
    "\n",
    "with tf.variable_scope('scope4'):\n",
    "    v = tf.Variable(initial_value=[1., 2.], name='v')\n",
    "    v1 = tf.Variable(initial_value=[1., 2.], name='v')\n",
    "    v2 = tf.get_variable(name='v2', initializer=tf.zeros_initializer, shape=[1, 2], dtype=tf.float32)\n",
    "\n",
    "print(v.name)\n",
    "print(v1.name)\n",
    "print(v2.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Tensor attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it was mentioned in the beginning of notebook, **rank** and **shape** are two attributes of tensors. We can run a session on `tf.rank` and `tf.shape` to get these attributes with a nice format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a_0 = tf.constant(np.random.randint(0 , 5, ()), dtype=tf.float64)  # tensor with rank 0, scalar\n",
    "a_1 = tf.constant(np.random.randint(0 , 5, (6)), dtype=tf.float64)  # tensor with rank 1, vector\n",
    "a_2 = tf.constant(np.random.randint(0 , 5, (3,6)), dtype=tf.float64)  # tensor with rank 2, matrix\n",
    "\n",
    "\n",
    "a_0_rank = tf.rank(a_0)   # return 0d-Tensor, type int32 ,scaler\n",
    "a_1_rank = tf.rank(a_1)    \n",
    "a_2_rank = tf.rank(a_2)    \n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    a,b,c = sess.run([a_0_rank, a_1_rank, a_2_rank])\n",
    "    \n",
    "print(a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.truncated_normal((2,4,5))  # tf.truncated_normal is a random initializer in Tensorflow\n",
    "\n",
    "shape = tf.shape(a)  # 1d-tensor containing shape of a\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    shape_r = sess.run(shape)\n",
    "    \n",
    "print(shape_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful mathematical functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `tf.reduce_sum`\n",
    "\n",
    "* `tf.reduce_mean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.get_variable(name='x', initializer=[[1, 1, 1], [1, 1, 1]])\n",
    "y = tf.get_variable(name='y', initializer=[[1, 3], [1, 3], [1, 3]])\n",
    "a = tf.matmul(x, y)\n",
    "s = tf.reduce_sum(a)\n",
    "s0 = tf.reduce_sum(a, axis=1)\n",
    "s1 = tf.reduce_sum(a, axis=0)\n",
    "m = tf.reduce_mean(a)\n",
    "m0 = tf.reduce_mean(a, axis=0)\n",
    "m1 = tf.reduce_mean(a, axis=1, keepdims=True)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    x_np, y_np, a_np, s_np, s0_np, s1_np, m_np, m0_np, m1_np = sess.run([x, y, a, s, s0, s1, m, m0, m1])\n",
    "\n",
    "print('x_np:\\n', x_np)\n",
    "print('y_np:\\n', y_np)\n",
    "print('a_np:\\n', a_np)\n",
    "print('s_np:\\n', s_np)\n",
    "print('s0_np:\\n', s0_np)\n",
    "print('s1_np:\\n', s1_np)\n",
    "print('m_np:\\n', m_np)\n",
    "print('m0_np:\\n', m0_np)\n",
    "print('m1_np:\\n', m1_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
